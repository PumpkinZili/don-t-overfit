{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# General information\n",
    "\n",
    "In Don't Overfit! II competition we have a binary classification task. 300 columns, 250 training samples and 79 times more samples in test data! We need to be able to build a model without overfitting.\n",
    "\n",
    "In this kernel I'll write the following things:\n",
    "\n",
    "* EDA on the features and trying to get some insights;\n",
    "* Using permutation importance to select most impactful features;\n",
    "* Comparing various models: bayer classification, linear models, tree based models;\n",
    "* Trying various approaches to feature selection including taking top features from eli5 and shap;\n",
    "* Hyperparameter optimization for models;\n",
    "* Feature generation;\n",
    "* Other things;\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*vuZxFMi5fODz2OEcpG-S1g.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "# import shap\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1c971fbc1a1b8249045b120924058402a036e665"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 302)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b40dd26ead2705ebf0058b0aa528c89a18aedbe"
   },
   "source": [
    "\n",
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67a26174603f6a28709b7e0431aa431832ae608d"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "504b609f61494c21f8b078182e06191581ecb2a6"
   },
   "outputs": [],
   "source": [
    "train[train.columns[2:]].std().plot('hist');\n",
    "plt.title('Distribution of stds of all columns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7b0f65d2d5c999a44a3f71e013b1b6a6ff08980"
   },
   "outputs": [],
   "source": [
    "train[train.columns[2:]].mean().plot('hist');\n",
    "plt.title('Distribution of means of all columns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d205e01b009224a3189903e1858dd592fb222d2d"
   },
   "outputs": [],
   "source": [
    "# we have no missing values\n",
    "train.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30e64cca712542d662201263914d8fc25496563e"
   },
   "outputs": [],
   "source": [
    "print('Distributions of first 28 columns')\n",
    "plt.figure(figsize=(26, 24))\n",
    "for i, col in enumerate(list(train.columns)[2:30]):\n",
    "    plt.subplot(7, 4, i + 1)\n",
    "    plt.hist(train[col])\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "227daacd39977e5658c7e27db2686d8f65fdff3c"
   },
   "outputs": [],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89e9ed49ceff33d27cd1888336c3c46a38c5c8aa"
   },
   "source": [
    "From this overview we can see the following things:\n",
    "* target is binary and has some disbalance: 36% of samples belong to 0 class;\n",
    "* values in columns are more or less similar;\n",
    "* columns have std of 1 +/- 0.1 (min and max values are 0.889, 1.117 respectively);\n",
    "* columns have mean of 0 +/- 0.15 (min and max values are -0.2, 0.1896 respectively);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06df27b43428261da7daf02e708b934519d78ac2"
   },
   "source": [
    "Let's have a look at correlations now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae63462aa70238f0a2858de687dc7d2ae319589a"
   },
   "outputs": [],
   "source": [
    "corrs = train.corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "corrs = corrs[corrs['level_0'] != corrs['level_1']]\n",
    "corrs.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2d921a5d3bf606b88853988c10acad020685334"
   },
   "source": [
    "We can see that correlations between features are lower that 0.3 and the most correlated feature with target has correlation of 0.37. So we have no highly correlated features which we could drop, on the other hand we could drop some columns with have little correlation with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4f28e1e3c847e2fe165034dd870154afb7fe939"
   },
   "source": [
    "## Basic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8f3eef02d6beac1b76f88c75bb842da9a313f592"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "n_fold = 20\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "repeated_folds = RepeatedStratifiedKFold(n_splits=20, n_repeats=20, random_state=42)\n",
    "# X_train += np.random.normal(0, 0.1, X_train.shape)\n",
    "scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "32b8fe75f240c11df7eaf3ed91b76d9260f999c9"
   },
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params, folds=folds, model_type='lgb', plot_feature_importance=False, averaging='usual', model=None):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "                  \n",
    "            \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "#             print(X_train.shape)\n",
    "#             print(y_train.shape)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n",
    "            # print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe9017199e72183e9686e55a3608c9339b779302",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A lot of people are using logreg currently, let's try\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "# model = linear_model.Lasso(alpha=0.03, tol=0.01, selection='random', random_state=42)\n",
    "# model = linear_model.LogisticRegressionCV(cv=5, class_weight='balanced', penalty='l1', Cs=20, solver='liblinear', multi_class='ovr')\n",
    "oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open('./scores_sklearn.csv','w+')\n",
    "b = open('./prediction_lr_repeated_sklearn.csv','w+')\n",
    "i = 0\n",
    "for x in prediction_lr:\n",
    "    b.write(str(x)+'\\n')\n",
    ".        i+=1\n",
    "for y in scores:\n",
    "    c.write(str(y)+'\\n')\n",
    "print(i)\n",
    "b.close()\n",
    "\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eta=0.8, gamma=2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=2, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0.5,\n",
       "       reg_lambda=0.5, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "m = XGBClassifier(\n",
    "    max_depth=2,\n",
    "    gamma=2,\n",
    "    eta=0.8,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=0.5\n",
    ")\n",
    "m.fit(X_train, y_train)\n",
    "# m.predict_proba(test[labels])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='old', bootstrap=False, contamination='legacy',\n",
       "        max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,\n",
       "        random_state=1, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isf = IsolationForest(n_jobs=-1, random_state=1)\n",
    "isf.fit(X_train, y_train)\n",
    "\n",
    "# print(isf.score_samples(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "arr = isf.predict(X_train)\n",
    "arr = np.array(np.where(arr==-1))\n",
    "arr=arr.reshape(-1)\n",
    "print(arr.shape)\n",
    "X_train = X_train.drop(arr)\n",
    "y_train = y_train.drop(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features:\n",
      "1. feature 33 (0.048426)\n",
      "2. feature 65 (0.023535)\n",
      "3. feature 117 (0.013435)\n",
      "4. feature 116 (0.009164)\n",
      "5. feature 4 (0.008982)\n",
      "6. feature 217 (0.008768)\n",
      "7. feature 91 (0.008572)\n",
      "8. feature 39 (0.008474)\n",
      "9. feature 119 (0.008161)\n",
      "10. feature 80 (0.008042)\n",
      "11. feature 189 (0.008041)\n",
      "12. feature 259 (0.007760)\n",
      "13. feature 252 (0.007628)\n",
      "14. feature 90 (0.007457)\n",
      "15. feature 243 (0.007179)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "TOP_FEATURES = 15\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250, max_depth=5, random_state=1)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std(\n",
    "    [tree.feature_importances_ for tree in forest.estimators_],\n",
    "    axis=0\n",
    ")\n",
    "indices = np.argsort(importances)[::-1]\n",
    "indices = indices[:TOP_FEATURES]\n",
    "indices\n",
    "print('Top features:')\n",
    "for f in range(TOP_FEATURES):\n",
    "    print('%d. feature %d (%f)' % (f + 1, indices[f], importances[indices[f]]))\n",
    "# print(X_train.shape)\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 15)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[[str(x) for x in indices]]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19750, 15)\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test[[str(x) for x in indices]]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train += np.random.normal(0, 0.1, X_train.shape)\n",
    "# scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def column_or_1d(y, warn=False):\n",
    "    \"\"\" Ravel column or 1d numpy array, else raises an error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array-like\n",
    "\n",
    "    warn : boolean, default False\n",
    "       To control display of warnings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array\n",
    "\n",
    "    \"\"\"\n",
    "    shape = np.shape(y)\n",
    "    if len(shape) == 1:\n",
    "        return np.ravel(y)\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        if warn:\n",
    "            warnings.warn(\"A column-vector y was passed when a 1d array was\"\n",
    "                          \" expected. Please change the shape of y to \"\n",
    "                          \"(n_samples, ), for example using ravel().\",\n",
    "                          DataConversionWarning, stacklevel=2)\n",
    "        return np.ravel(y)\n",
    "\n",
    "    raise ValueError(\"bad input shape {0}\".format(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.53122447 -0.8243413   0.66764043 ...  0.70410223 -1.75202764\n",
      "  -0.90105456]\n",
      " [-2.59022291  1.24906648  0.93468203 ...  0.90164791 -0.03303986\n",
      "   1.27261372]\n",
      " [ 1.07290513  0.95956002 -0.3870293  ...  0.6312213   0.72561371\n",
      "  -0.60185662]\n",
      " ...\n",
      " [ 0.14531469 -1.08364745  1.63361763 ... -1.01723024 -0.54821371\n",
      "  -0.16580159]\n",
      " [-0.48882353 -0.41090941 -0.40245408 ... -0.77077763 -0.83558248\n",
      "   0.95170742]\n",
      " [-0.45867433  0.48156195  1.2325732  ...  0.0663941   0.39644584\n",
      "   1.25939993]]\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "7      1.0\n",
      "8      1.0\n",
      "9      1.0\n",
      "10     0.0\n",
      "11     1.0\n",
      "12     1.0\n",
      "13     0.0\n",
      "14     0.0\n",
      "15     1.0\n",
      "16     1.0\n",
      "17     0.0\n",
      "18     1.0\n",
      "19     1.0\n",
      "20     1.0\n",
      "21     1.0\n",
      "22     0.0\n",
      "24     1.0\n",
      "25     1.0\n",
      "26     1.0\n",
      "27     1.0\n",
      "29     1.0\n",
      "30     1.0\n",
      "31     1.0\n",
      "32     1.0\n",
      "33     1.0\n",
      "      ... \n",
      "216    1.0\n",
      "217    1.0\n",
      "218    0.0\n",
      "219    1.0\n",
      "220    1.0\n",
      "221    1.0\n",
      "222    1.0\n",
      "223    1.0\n",
      "224    1.0\n",
      "225    0.0\n",
      "227    0.0\n",
      "228    0.0\n",
      "229    1.0\n",
      "230    1.0\n",
      "231    1.0\n",
      "232    1.0\n",
      "233    0.0\n",
      "234    0.0\n",
      "235    1.0\n",
      "237    1.0\n",
      "238    1.0\n",
      "239    0.0\n",
      "240    0.0\n",
      "241    1.0\n",
      "243    0.0\n",
      "244    0.0\n",
      "245    0.0\n",
      "246    0.0\n",
      "248    1.0\n",
      "249    0.0\n",
      "Name: target, Length: 225, dtype: float64\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "X_train=np.where(np.abs(X_train)< 0.000001, 0.1, X_train)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "# np.any(np.isnan(X_train))\n",
    "# np.all(np.isfinite(X_train))\n",
    "# print(np.isnan(y_train).any())\n",
    "# \n",
    "# y = column_or_1d(y_train, warn=True)\n",
    "# print(np.isnan(y_train).any())\n",
    "print(y_train.dtype.kind in 'fc')\n",
    "# print(np.isfinite(y.sum()))\n",
    "# print(np.isinf(y).any())\n",
    "# print(np.isfinite(y).all())\n",
    "# y = np.asanyarray(y)\n",
    "# print(y)\n",
    "# print(y_train.shape)\n",
    "# print(np.isnan(y_train).any())\n",
    "# print(y.dtype.kind in 'fc')\n",
    "# print(np.isfinite(y.sum()))\n",
    "# print(np.isinf(y).any())\n",
    "# print(np.isfinite(y).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Top feature importances')\n",
    "plt.bar(\n",
    "    range(TOP_FEATURES), \n",
    "    importances[indices],\n",
    "    yerr=std[indices], \n",
    ")\n",
    "plt.xticks(range(TOP_FEATURES), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "fe9017199e72183e9686e55a3608c9339b779302",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-0bf28afcbcae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model = linear_model.Lasso(alpha=0.03, tol=0.01, selection='random', random_state=42)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# model = linear_model.LogisticRegressionCV(cv=5, class_weight='balanced', penalty='l1', Cs=20, solver='liblinear', multi_class='ovr')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moof_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepeated_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sklearn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-18104fc73b97>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X, X_test, y, params, folds, model_type, plot_feature_importance, averaging, model)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#             print(X_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#             print(y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0my_pred_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1288\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1289\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    761\u001b[0m                         dtype=None)\n\u001b[0;32m    762\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     56\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# A lot of people are using logreg currently, let's try\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "# model = linear_model.Lasso(alpha=0.03, tol=0.01, selection='random', random_state=42)\n",
    "# model = linear_model.LogisticRegressionCV(cv=5, class_weight='balanced', penalty='l1', Cs=20, solver='liblinear', multi_class='ovr')\n",
    "oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, folds=repeated_folds, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open('./scores_sklearn.csv','w+')\n",
    "b = open('./prediction_lr_repeated_sklearn.csv','w+')\n",
    "i = 0\n",
    "for x in prediction_lr:\n",
    "    b.write(str(x)+'\\n')\n",
    "    if x<0.1 or x>0.9:\n",
    "        i+=1\n",
    "for y in scores:\n",
    "    c.write(str(y)+'\\n')\n",
    "print(i)\n",
    "b.close()\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(XGBClassifier(n_jobs=-1, random_state=1))\n",
    "\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "print('Selected features:')\n",
    "print(X_train[rfe.support_].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "600682b545014ae67e19a8b04724e75767be6014"
   },
   "source": [
    "## ELI5 and permutation importance\n",
    "\n",
    "ELI5 is a package with provides explanations for ML models. It can do this not only for linear models, but also for tree based like Random Forest or lightgbm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b97e881aec4c17fda9e106bd2970c763d65abe5d"
   },
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model, random_state=1).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f16f5fee606cb48d35c0cb95e123c7542aacac28"
   },
   "outputs": [],
   "source": [
    "(model.coef_ != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c738de31f86152ced6cb35ddb8d3569e7b49a6e"
   },
   "source": [
    "We can see that There are several features with highly positive weights and more features with negative weights. In fact there are only 32 features, which are important according to ELI5. It is worth noticing though, that the model itself had 34 non-zero features, so ELI5 dropped only 2 features.. Let's try using only them for the submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c78622313d2963bb28aa2870e0ed9f811f315ba"
   },
   "outputs": [],
   "source": [
    "top_features = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i]\n",
    "X_train = train[top_features]\n",
    "X_test = test[top_features]\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86e7050847ae7d7462e728d97922a1072c013765",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open('./scores_v1.csv','w+')\n",
    "b = open('./prediction_lr_repeated_v1.csv','w+')\n",
    "for x in prediction_lr:\n",
    "    if x > 0.5:\n",
    "        b.write('1'+'\\n')\n",
    "    else:\n",
    "        b.write('0'+'\\n')\n",
    "\n",
    "for y in scores:\n",
    "    c.write(str(y)+'\\n')\n",
    "value_cou = pd.read_csv('./prediction_lr_repeated_v1.csv')\n",
    "print(value_cou[value_cou.columns[0]].value_counts())\n",
    "b.close()\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0eebf500fd8e7cfbb9ea41bfc35cc500da31e542"
   },
   "source": [
    "Wow, we got improvement from 0.7226 to 0.7486 on CV! But this submission gives 0.845 on leaderboard. So it decreases score slightly. Let's try other things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbee2b85bae60cf0607b977692306eb380582e5c"
   },
   "source": [
    "### Permutation importance\n",
    "There is also another way of using eli5 - we could have a look at permutation importance. It works in the following way:\n",
    "* We fit a model;\n",
    "* We randomly shuffle one column of validation data and calculate the score;\n",
    "* If the score dropped significantly, it means that the feature is important;\n",
    "\n",
    "You can read more about this approach here: https://www.kaggle.com/dansbecker/permutation-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "242439bf4036359fc07864ac41d0bccac6f1d9c6"
   },
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model, random_state=1).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26dd053929c39014a3244d8d2471e8b2cdb5ac0f"
   },
   "outputs": [],
   "source": [
    "top_features = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(perm).feature if 'BIAS' not in i]\n",
    "X_train = train[top_features]\n",
    "X_test = test[top_features]\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcbc3e88b57bab0d1220c41d222540d42a445622"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr1, prediction_lr1, _ = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open('./scores_v2.csv','w+')\n",
    "b = open('./prediction_lr_repeated_v2.csv','w+')\n",
    "for x in prediction_lr1:\n",
    "    if x > 0.5:\n",
    "        b.write('1'+'\\n')\n",
    "    else:\n",
    "        b.write('0'+'\\n')\n",
    "\n",
    "for y in scores:\n",
    "    c.write(str(y)+'\\n')\n",
    "value_cou = pd.read_csv('./prediction_lr_repeated_v2.csv')\n",
    "print(value_cou[value_cou.columns[0]].value_counts())\n",
    "b.close()\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ba3da8d6a72868c99fd03de89c4f636d48836d7"
   },
   "source": [
    "Wow, if we select columns by permutation importance, CV score drops significantly. It seems it doesn't work well in out case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a010cfbba09f2846f05211678657f87614c219c4"
   },
   "source": [
    "## SHAP\n",
    "\n",
    "Another interesting tool is SHAP. It also provides explanations for a variety of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "5869cb071f42e20e9e420c0a9d1ef584dd2b2417"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open('./scores_v3.csv','w+')\n",
    "b = open('./prediction_lr_repeated_v3.csv','w+')\n",
    "for x in prediction_lr:\n",
    "    if x > 0.5:\n",
    "        b.write('1'+'\\n')\n",
    "    else:\n",
    "        b.write('0'+'\\n')\n",
    "\n",
    "for y in scores:\n",
    "    c.write(str(y)+'\\n')\n",
    "value_cou = pd.read_csv('./prediction_lr_repeated_v3.csv')\n",
    "print(value_cou[value_cou.columns[0]].value_counts())\n",
    "b.close()\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33c4481d2b911208738c7ffc7042259108bb5736",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f1aa2616547304144c41566d74c17e922325ba64"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd6ac9eda7175a382b6b0adf4e5fe95ecd02e553"
   },
   "source": [
    "It could be difficult to interpret this plot when you see it for the first time. It shows how features impact predictions. For example for feature 33 low values have a negative impact on model predictions (zero is more likely), and high values have a positive impace (ones are more likely). Feature 217 has an opposite effect: low values have a positive impact and high values have a negative impact.\n",
    "\n",
    "But we will need to select features manually... let's use a library for that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb5994704ef34d093e24d4a3983de73b6c98c1bd"
   },
   "source": [
    "### Mlextend SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46b0caca758e3864e8820e8e21af53a103890444",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sfs1 = SFS(model, \n",
    "           k_features=(10, 15), \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=0,\n",
    "           scoring='roc_auc',\n",
    "           cv=folds,\n",
    "          n_jobs=-1)\n",
    "\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28fc74c03bd5502f575d2121624737d78f626cfb"
   },
   "outputs": [],
   "source": [
    "fig1 = plot_sfs(sfs1.get_metric_dict(), kind='std_dev')\n",
    "\n",
    "plt.ylim([0.8, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1f69c3eec7c039557ba893e3572f3c95090044b"
   },
   "outputs": [],
   "source": [
    "top_features = list(sfs1.k_feature_names_)\n",
    "X_train = train[top_features]\n",
    "X_test = test[top_features]\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open('./scores_v4.csv','w+')\n",
    "b = open('./prediction_lr_repeated_v4.csv','w+')\n",
    "for x in prediction_lr:\n",
    "    if x > 0.5:\n",
    "        b.write('1'+'\\n')\n",
    "    else:\n",
    "        b.write('0'+'\\n')\n",
    "\n",
    "for y in scores:\n",
    "    c.write(str(y)+'\\n')\n",
    "value_cou = pd.read_csv('./prediction_lr_repeated_v4.csv')\n",
    "print(value_cou[value_cou.columns[0]].value_counts())\n",
    "b.close()\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fcfda893ab182e944fa333b8540021c4a32b9abe"
   },
   "source": [
    "And this gives 0.811 on leaderboard. Overfitting! It seems that feature selection isn't the best approach. Let's try building various models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ebbe316febc785339dde063c927c297d124ef72"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "af8a61dc9fc0d142b234374439c9666972d7a32b"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afce168ca97864abaac48bbb07820edfc89e7b2b"
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "parameter_grid = {'class_weight' : ['balanced', None],\n",
    "                  'penalty' : ['l2'],\n",
    "                  'C' : [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "                  'solver': ['newton-cg', 'sag', 'lbfgs']\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(lr, param_grid=parameter_grid, cv=folds, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e09d949518bb82ecfa07e8b0a87dce72f286ade"
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LogisticRegression(solver='liblinear', max_iter=10000)\n",
    "\n",
    "parameter_grid = {'class_weight' : ['balanced', None],\n",
    "                  'penalty' : ['l2', 'l1'],\n",
    "                  'C' : [0.001, 0.01, 0.08, 0.1, 0.15, 1.0, 10.0, 100.0],\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(lr, param_grid=parameter_grid, cv=folds, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d93e5cda1dd01559d79eca69516240b2f609e3a"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ade6c06755d1664f1ce194bdb7325ea9f7bb94c"
   },
   "source": [
    "So, parameters for logreg are optimal, let's try other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f035ad28718fe9f932b4ea63637a3ac3c1bd9d1"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "oof_gnb, prediction_gnb, scores_gnb = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d00ff4a78c464d35a25c101c4f2f03efc453c615"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "parameter_grid = {'n_estimators': [5, 10, 20, 50, 100],\n",
    "                  'learning_rate': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(abc, param_grid=parameter_grid, cv=folds, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcb3555d31230c73b1ab65f5371455a0bdd68999",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(**grid_search.best_params_)\n",
    "oof_abc, prediction_abc, scores_abc = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f57a2c0f0da71197a1163a8bed02efc0c8d89e3b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "parameter_grid = {'n_estimators': [10, 50, 100, 1000],\n",
    "                  'max_depth': [None, 3, 5, 15]\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(etc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "etc = ExtraTreesClassifier(**grid_search.best_params_)\n",
    "oof_etc, prediction_etc, scores_etc = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a529bdac93c14d7cf4430037016784c5f913b8c"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "parameter_grid = {'n_estimators': [10, 50, 100, 1000],\n",
    "                  'max_depth': [None, 3, 5, 15]\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(rfc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "rfc = RandomForestClassifier(**grid_search.best_params_)\n",
    "oof_rfc, prediction_rfc, scores_rfc = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd36b69df66bb55c2506eb40bf42fd64698d583f"
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "gpc = GaussianProcessClassifier()\n",
    "oof_gpc, prediction_gpc, scores_gpc = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=gpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67f9ca1934727e6cbe6434d7d911e9134acf6556"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability=True, gamma='scale')\n",
    "\n",
    "parameter_grid = {'C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "                  'kernel': ['linear', 'poly', 'rbf'],\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "svc = SVC(probability=True, gamma='scale', **grid_search.best_params_)\n",
    "oof_svc, prediction_svc, scores_svc = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e6940fd73f9064824626c17e0abd117824bf261"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "parameter_grid = {'n_neighbors': [2, 3, 5, 10, 20],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'leaf_size': [5, 10, 30]\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(knc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "knc = KNeighborsClassifier(**grid_search.best_params_)\n",
    "oof_knc, prediction_knc, scores_knc = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad1c850d35de23d06d5c267b5c3082188d1f9999"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "parameter_grid = {'alpha': [0.0001, 1, 2, 10]\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(bnb, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "bnb = BernoulliNB(**grid_search.best_params_)\n",
    "oof_bnb, prediction_bnb, scores_bnb = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54452c184551d9d2ad94f4dc468f92e75cc3f984"
   },
   "outputs": [],
   "source": [
    "sgd = linear_model.SGDClassifier(eta0=1, max_iter=1000, tol=0.0001)\n",
    "\n",
    "parameter_grid = {'loss': ['log', 'modified_huber'],\n",
    "                  'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                  'alpha': [0.001, 0.01],\n",
    "                  'l1_ratio': [0, 0.15, 0.5, 1.0],\n",
    "                  'learning_rate': ['optimal', 'invscaling', 'adaptive']\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(sgd, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "sgd = linear_model.SGDClassifier(eta0=1, tol=0.0001, **grid_search.best_params_)\n",
    "oof_sgd, prediction_sgd, scores_sgd = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2335b870061080430fc25c9e99111357088824b8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8));\n",
    "scores_df = pd.DataFrame({'LogisticRegression': scores})\n",
    "scores_df['GaussianNB'] = scores_gnb\n",
    "scores_df['AdaBoostClassifier'] = scores_abc\n",
    "scores_df['ExtraTreesClassifier'] = scores_etc\n",
    "scores_df['GaussianProcessClassifier'] = scores_gpc\n",
    "scores_df['SVC'] = scores_svc\n",
    "scores_df['KNeighborsClassifier'] = scores_knc\n",
    "scores_df['BernoulliNB'] = scores_bnb\n",
    "scores_df['SGDClassifier'] = scores_sgd\n",
    "scores_df['RandomForestClassifier'] = scores_rfc\n",
    "\n",
    "sns.boxplot(data=scores_df);\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f81c4775a537def6405793464109d7e80f32697"
   },
   "source": [
    "We can see that logistic regression is superior to most other models. Only SVC is comparable. It seems that other models either overfit or can't work on this small dataset.\n",
    "\n",
    "\n",
    "Let's try submitting a blend of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "eb67be43e33c0af7539ad43e47f73c7a261e0aea"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "596ac8130214fb6a70d1f1bfa12215fdca4421c5"
   },
   "outputs": [],
   "source": [
    "# submission = pd.read_csv('../input/sample_submission.csv')\n",
    "# submission['target'] = (prediction_lr + prediction_svc) / 2\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0b1fd02763ea153770d4c8c496708719b85528a"
   },
   "outputs": [],
   "source": [
    "plt.hist(prediction_lr, label='logreg');\n",
    "plt.hist(prediction_svc, label='svc');\n",
    "plt.hist((prediction_lr + prediction_svc) / 2, label='blend');\n",
    "plt.title('Distribution of out of fold predictions');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27fe8ff687b97b8b77e00c2674d73af7dc0c8870"
   },
   "source": [
    "Sadly blend gives 0.831 on LB. Again no luck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fab09097febdb8a9818c7d3f040aae6fe853484"
   },
   "source": [
    "Let's try generating some features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac1ba90583579cbe3ad953280b7f8134f218dbc8"
   },
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e0113dcf9a8fe6a4c88fa1d03dbedb0412440e3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eed696b6f14c7fe3c0012994073ff50f4b753045"
   },
   "source": [
    "The number of polynomial features is ~45k which is too much. We need some way to select some of them. Let's try use correlations with target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d0527be4dbc026aa059d1da2fed0b4b25eda269"
   },
   "outputs": [],
   "source": [
    "cor = pd.DataFrame(X_train_poly).corrwith(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b9691673c8833ee652567e7d4c09c675a6430a76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = []\n",
    "for i in range(10, 510, 5):\n",
    "    top_corr_cols = list(cor.abs().sort_values().tail(i).reset_index()['index'].values)\n",
    "    X_train_poly1 = X_train_poly[:, top_corr_cols]\n",
    "    X_test_poly1 = X_test_poly[:, top_corr_cols]\n",
    "    oof_lr_poly, prediction_lr_poly, scores = train_model(X_train_poly1, X_test_poly1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    sc.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "cf28344a6d0b663d2ba57724bc526611096ebf01"
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(10, 510, 5)),\n",
    "        y = [np.round(np.mean(i), 4) for i in sc],\n",
    "        name = 'CV scores'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N poly features vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18e458397141b8269fd4bd711ab5bbc540face79"
   },
   "source": [
    "Not suprisingly we overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b80ab00ed812cfb5509c200cf17825efffc83f60"
   },
   "outputs": [],
   "source": [
    "top_corr_cols = list(cor.abs().sort_values().tail(300).reset_index()['index'].values)\n",
    "X_train_poly1 = X_train_poly[:, top_corr_cols]\n",
    "X_test_poly1 = X_test_poly[:, top_corr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26f39c9dc3fd3ae4b11cf0501c1fab1399bc6fc8"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr_poly, prediction_lr_poly, scores = train_model(X_train_poly1, X_test_poly1, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11c41e8fb3cc63aa6e13528e13da298cf9557713"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = prediction_lr_poly\n",
    "# submission.to_csv('submission_poly.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9aeaf79451f9b2bc68851795b6abadff4fe7351"
   },
   "source": [
    "Score became much lower. So this is also a bad idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03af3b65d3f687689051ac93662029c4e2f58600"
   },
   "source": [
    "### Adding statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a197ee822f72ac1afbdb619e795195300a1b47c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "X_train['300'] = X_train.std(1)\n",
    "X_test['300'] = X_test.std(1)\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr_1, prediction_lr_1, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1afb310da8f11a8fcc5fdc4a6a3836176fd3ac98"
   },
   "source": [
    "Let's compare with repeated KFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57dd2ffc7c366e301c77145eba46c62ed6d114bd"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "X_train['300'] = X_train.std(1)\n",
    "X_test['300'] = X_test.std(1)\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr_1, prediction_lr_1_repeated, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_folds)\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = prediction_lr_1_repeated\n",
    "submission.to_csv('repeated_fold_features.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa509eaef0a1e7152f00103d1d7e02775893aa2e"
   },
   "source": [
    "CV increased a bit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "690f4e5f6cf2bdb293f6fca2c3c4e1e570670733"
   },
   "source": [
    "### Adding distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "938d99d96431cbba45756bbe4cc2ff09184def66"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "main_cols = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24bebe8ebc23129858024eb89f2e54868e0cc689",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(5, n_jobs=-1)\n",
    "neigh.fit(X_train)\n",
    "\n",
    "dists, _ = neigh.kneighbors(X_train, n_neighbors=5)\n",
    "mean_dist = dists.mean(axis=1)\n",
    "max_dist = dists.max(axis=1)\n",
    "min_dist = dists.min(axis=1)\n",
    "\n",
    "X_train['300'] = X_train.std(1)\n",
    "X_train = np.hstack((X_train, mean_dist.reshape(-1, 1), max_dist.reshape(-1, 1), min_dist.reshape(-1, 1)))\n",
    "\n",
    "test_dists, _ = neigh.kneighbors(X_test, n_neighbors=5)\n",
    "\n",
    "test_mean_dist = test_dists.mean(axis=1)\n",
    "test_max_dist = test_dists.max(axis=1)\n",
    "test_min_dist = test_dists.min(axis=1)\n",
    "\n",
    "X_test['300'] = X_test.std(1)\n",
    "X_test = np.hstack((X_test, test_mean_dist.reshape(-1, 1), test_max_dist.reshape(-1, 1), test_min_dist.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d96c7e49b6e4048f200dd18e4975466b983e3fd3"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr_2, prediction_lr_2, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)\n",
    "submission['target'] = prediction_lr_2\n",
    "submission.to_csv('nn_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ec33fc61e002ff5f963fc3c71c9d3da5f82d7ef"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = (prediction_lr_1 + prediction_lr_2) / 2\n",
    "# submission.to_csv('blend.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "191f51d36b953c8b555bd12edd6a298bbb2a193e"
   },
   "source": [
    "## Sklearn feature selection\n",
    "\n",
    "Sklearn has several methods to do feature selection. Let's try some of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb4551a447ecefb4f2ff7aba6d0b3cdc5abee197",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline score\n",
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr_1, prediction_lr_1, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "6d268e80c10bea5245806741fd18e8534cfdb9c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_dict = {'f_classif': [], 'mutual_info_classif': []}\n",
    "for i in range(5, 100, 5):\n",
    "    s1 = SelectPercentile(f_classif, percentile=i)\n",
    "    X_train1 = s1.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s1.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['f_classif'].append(np.mean(scores))\n",
    "    \n",
    "    s2 = SelectPercentile(mutual_info_classif, percentile=i)\n",
    "    X_train1 = s2.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s2.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['mutual_info_classif'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "dfc7618d9ed474ee4569aa79b0cdc9c98efa471e"
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(5, 100, 5)),\n",
    "        y = scores_dict['f_classif'],\n",
    "        name = 'CV scores f_classif'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(5, 100, 5)),\n",
    "        y = scores_dict['mutual_info_classif'],\n",
    "        name = 'CV scores mutual_info_classif')]\n",
    "layout = go.Layout(dict(title = \"Top N features by percentile vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features by percentile'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "65f03bc1fe3bd975d0ec4ad5bf782a4e8a04c444",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_dict = {'f_classif': [], 'mutual_info_classif': []}\n",
    "for i in range(10, 301, 10):\n",
    "    s1 = SelectKBest(f_classif, k=i)\n",
    "    X_train1 = s1.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s1.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['f_classif'].append(np.mean(scores))\n",
    "    \n",
    "    s2 = SelectKBest(mutual_info_classif, k=i)\n",
    "    X_train1 = s2.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s2.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['mutual_info_classif'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4c3f3c18f6d3fd4b537876e1a2ddc068f755845d"
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(10, 301, 10)),\n",
    "        y = scores_dict['f_classif'],\n",
    "        name = 'CV scores f_classif'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(10, 301, 10)),\n",
    "        y = scores_dict['mutual_info_classif'],\n",
    "        name = 'CV scores mutual_info_classif')]\n",
    "layout = go.Layout(dict(title = \"Top N features by SelectKBest vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features by SelectKBest'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae28a13e61b4a49b3450aab6fc9e0643385e4790"
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=60)\n",
    "X_trainK = selector.fit_transform(X_train, y_train.values.astype(int))\n",
    "X_testK = selector.transform(X_test)\n",
    "oof_lr_1, prediction_lr_1, scores = train_model(X_trainK, X_testK, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "610aac831f9d5b4e419729f7655f947cbd4a5f71"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = prediction_lr_1\n",
    "# submission.to_csv('top_n_features.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "c6da95040189d16d4dea04902378af6a4a3a2049",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_list = []\n",
    "for i in range(10, 301, 5):\n",
    "    s = RFE(model, i, step=1)\n",
    "    X_train1 = s.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_list.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ce0ea15ac66bfc710d77430137a652b73e55368c"
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(10, 301, 5)),\n",
    "        y = scores_list,\n",
    "        name = 'CV scores RFE'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N features by RFE vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features by RFE'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae28a13e61b4a49b3450aab6fc9e0643385e4790"
   },
   "outputs": [],
   "source": [
    "selector = RFE(model, 20, step=1)\n",
    "X_trainK = selector.fit_transform(X_train, y_train.values.astype(int))\n",
    "X_testK = selector.transform(X_test)\n",
    "oof_lr_1, prediction_lr_rfe_20, scores = train_model(X_trainK, X_testK, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "610aac831f9d5b4e419729f7655f947cbd4a5f71"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = prediction_lr_rfe_20\n",
    "submission.to_csv('rfe_20.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f09566d8b120c453df287f6e0ffc3ec4ce02f34"
   },
   "source": [
    "### GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22697edeca913a6fc486b11f7348eeae43d723b1"
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=55)\n",
    "X_trainK = selector.fit_transform(X_train, y_train.values.astype(int))\n",
    "X_testK = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b76fa19188b75a5db679f026bf01ee6d438891cc"
   },
   "outputs": [],
   "source": [
    "oof_glm, prediction_glm, scores = train_model(X_trainK, X_testK, y_train, params=None, model_type='glm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1455a96499a4ef25fb84cccb6a9c11f152feaf0"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = prediction_glm\n",
    "submission.to_csv('glm.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d1482994a31ac493f4f5889e52d547027d32f7c"
   },
   "source": [
    "### Selected top_features + statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5da819651ae126239b1c5349ef290c2ddc37e188",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eli5_weights = eli5.formatters.as_dataframe.explain_weights_df(model)\n",
    "eli5_weights['weight'] = eli5_weights['weight'].abs()\n",
    "eli5_weights = eli5_weights.sort_values('weight', ascending=False)\n",
    "eli5_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "f99e065338d8cd78ca739b21d1ea4a26d577d379"
   },
   "outputs": [],
   "source": [
    "train['mean'] = train.mean(1)\n",
    "train['std'] = train.std(1)\n",
    "test['mean'] = test.mean(1)\n",
    "test['std'] = test.std(1)\n",
    "\n",
    "scores_dict = {'simple': [], 'with_std': [], 'with_mean': []}\n",
    "for i in range(1, eli5_weights.shape[0] + 1):\n",
    "    top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:i]\n",
    "    \n",
    "    X_train = train[top_features]\n",
    "    X_test = test[top_features]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['simple'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['mean']]\n",
    "    X_test = test[top_features + ['mean']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['with_mean'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['std']]\n",
    "    X_test = test[top_features + ['std']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['with_std'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "766695d8f41ba8a090c7a4de39d91fdcb0fe24e4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['simple'],\n",
    "        name = 'Simple CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_mean'],\n",
    "        name = 'With mean CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_std'],\n",
    "        name = 'With std CV scores'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N features vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "1d73a5779b4fa314098255a8d5e7b83cbd5050c7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['mean'] = train.mean(1)\n",
    "train['std'] = train.std(1)\n",
    "test['mean'] = test.mean(1)\n",
    "test['std'] = test.std(1)\n",
    "\n",
    "scores_dict = {'simple': [], 'with_std': [], 'with_mean': []}\n",
    "for i in range(1, eli5_weights.shape[0] + 1):\n",
    "    top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:i]\n",
    "    \n",
    "    X_train = train[top_features]\n",
    "    X_test = test[top_features]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model, folds=repeated_folds)\n",
    "    scores_dict['simple'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['mean']]\n",
    "    X_test = test[top_features + ['mean']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_folds)\n",
    "    scores_dict['with_mean'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['std']]\n",
    "    X_test = test[top_features + ['std']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_folds)\n",
    "    scores_dict['with_std'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e8b60145a9e793fba0ef45cf9b3af18a7339ea92"
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['simple'],\n",
    "        name = 'Simple CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_mean'],\n",
    "        name = 'With mean CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_std'],\n",
    "        name = 'With std CV scores'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N features vs repeated folds CV\",\n",
    "                  xaxis = dict(title = 'Top N features'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "339d5901af5e8403987d343043661d83d58ab87f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:8]\n",
    "\n",
    "X_train = train[top_features + ['mean']]\n",
    "X_test = test[top_features + ['mean']]\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_folds)\n",
    "\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission_top8.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a40abaf1008de69645abc9aad68f65eaef94ef9b"
   },
   "outputs": [],
   "source": [
    "top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:10]\n",
    "\n",
    "X_train = train[top_features + ['mean']]\n",
    "X_test = test[top_features + ['mean']]\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_folds)\n",
    "\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission_top10.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
